---
keywords: gaussian splatting
---

# HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian Splatting

3D Gaussian + non-rigid tracking

- **Dynamic scene modeling**

  dual-graph mechanism to obtain motion priors
  - a coarse deformation graph for effective initialization
  - a fine-grained Gaussian graph to enforce subsequent constraints

  spatial-temporal regularizers to effectively balance the non-rigid prior and Gaussian updating

- **Compression** scheme with residual compensation, ~25x compression rate, with less than 2MB of storage per frame

## Related Work

**Dynamic**

- NeRF-family
- a few 3DGS recent work
  - Dynamic GS
  - [69, 72] implicit deformation network

**Compression**

- "A series of works are proposed for early point cloud compression with Octree [53, 63], Wavelet [41]. These are formalized into MPEG-PCC [54] standards by the Moving Picture Experts Group (MPEG), which are categorized into video-based (VPCC) and geometry-based (GPCC)."
- learning-based methods, e.g., tensor/scene decomposition, tri-planes and multi-planes

## Methods

**Coarse deformation graph**

- Non-rigid tracking
  - DynamicFusion, DoubleFusion
- Key-frame segementing (segmenting the data sequence into multiple key volumes)
  - Fusion4d: Real-time performance capture of challenging scenes ([link](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/a114-dou.pdf))
  - Flyfusion: Realtime dynamic scene reconstruction using a flying depth camera (Lan Xu, Yebin Liu)

**Fine-grained gaussian graph**

- initialize Gaussians from the NeuS2 mesh
- increase the sampling density in the hand and face regions to significantly improve visual quality
- **key-volume update strategy**
  - prune incorrect Gaussians from the previous keyframe and densify new ones at the current keyframe(?)
  - then restrict the number of Gaussians within the current segement
- Afterward, we establish a fine-grained Gaussian graph(?)

**4D Gaussians Optimization**

- not use the Gaussians' densification and pruning within the segment
- categorize attributes into two groups
  - appearance-aware parameters: scaling, opacity, SH
  - motion-aware parameters: position, rotation
- problem: temporal jitter
  - previous work: decoupling the deformation field from canonical 3D Gaussians (a fixed set of Gaussians across dynamic sequences)
    - -> substantially diminishes view-dependent effects and sacrifices rendering quality
  - this paper: introduce temporal and smooth regularization to delicately balance the dual graph prior and the updating of Gaussian attributes
    - temporal regularization: ensuring similar _appearance-aware parameters_ between adjacent frames
    - smooth regularization: _motion-aware parameters_, locally as-rigid-as-possible deformations
    - adaptive weight (on Gaussians) taking into account the displacement of positions between adjacent frames

**Compression**

- **residual compensation**
  - retain keyframe attributes and calculate residuals for non-keyframes
  - for appearance attributes: just use residual
  - for motion attributes: related to embedded deformation
- **quantization** attribute values
- **entropy encoding** Ranged Arithmetic Numerical System (RANS)

## Implementation Details

- BackgroundMattingV2 (prior to RVM)
- body, hands, face sampling ratio ~ 8:1:1 (~OpenPose)
- quantize appearance attributes and fix -> fine-tune motion attributes -> quantize motion
  - different quantization levels depending on key/non-key frames, appearance/motion parameters

## Experiments

81 Z-CAM, 4k 30fps
