---
keywords: gaussian splatting
---

# SparseGS: Real-Time 360Â° Sparse View Synthesis using Gaussian Splatting

We find that using naive depth priors is not sufficient and integrate depth priors with generative and explicit constraints to reduce background collapse, remove floaters, and enhance consistency from unseen viewpoints

direct floater pruning(?)

diffusion models to provide supervision in regions with little coverage from training views

apply depth constraints similar to prior work

## Related Work

1. constraints on the variantion between views
2. depth priors to novel views

## Methods

- alpha-blended depth vs. mode-selected depth. The former is a weighted sum of Gaussians' depth, while the latter is most opaque Gaussian's depth
- **depth loss** monocular estimation model predicts relative depth. Instead of estimating scale and shift to align, use Pearson correlation
  - between monocular depth and alpha-blended depth
- **SDS loss**(?)
- **floater pruning** when alpha-blended depth and mode-selected depth disagree. (pruning is done manually, case by case)
